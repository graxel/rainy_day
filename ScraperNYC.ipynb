{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2018-09-01\n",
      "1    2018-09-02\n",
      "2    2018-09-03\n",
      "3    2018-09-04\n",
      "4    2018-09-05\n",
      "5    2018-09-06\n",
      "6    2018-09-07\n",
      "7    2018-09-08\n",
      "8    2018-09-09\n",
      "9    2018-09-10\n",
      "10   2018-09-11\n",
      "11   2018-09-12\n",
      "12   2018-09-13\n",
      "13   2018-09-14\n",
      "14   2018-09-15\n",
      "15   2018-09-16\n",
      "16   2018-09-17\n",
      "17   2018-09-18\n",
      "18   2018-09-19\n",
      "19   2018-09-20\n",
      "20   2018-09-21\n",
      "21   2018-09-22\n",
      "22   2018-09-23\n",
      "23   2018-09-24\n",
      "24   2018-09-25\n",
      "25   2018-09-26\n",
      "26   2018-09-27\n",
      "27   2018-09-28\n",
      "28   2018-09-29\n",
      "29   2018-09-30\n",
      "30   2018-10-01\n",
      "31   2018-10-02\n",
      "32   2018-10-03\n",
      "33   2018-10-04\n",
      "34   2018-10-05\n",
      "35   2018-10-06\n",
      "36   2018-10-07\n",
      "37   2018-10-08\n",
      "38   2018-10-09\n",
      "dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import selenium\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "date_list = pd.Series(pd.date_range(datetime(2018,9,1), datetime.today()))\n",
    "print(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 19.442603 s\n",
      "[[3, 74.0, 69.0, 63.0]]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import selenium\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "def xpath(row=0,col=0,sub=0):\n",
    "    xpath = '//app/city-history/city-history-layout/div/div[2]/'\\\n",
    "            + 'section/div[2]/div[3]/div/div/div/div/'\\\n",
    "            + 'city-history-observation/div/div[2]/table'\\\n",
    "            + '/tbody/tr/td[' + str(col+1) + ']'\\\n",
    "            + '/table/tbody/tr[' + str(row+1) + ']'\\\n",
    "            + '/td[' + str(sub+1) + ']'\n",
    "    return xpath\n",
    "\n",
    "\n",
    "chromedriver = '/Users/grazillionaire/Documents/chromedriver' # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "\n",
    "\n",
    "# Generate list of dates (months) to pull weather data for.\n",
    "\n",
    "# For Chicago\n",
    "#city = 'il/chicago/KORD'\n",
    "#start_date = datetime(2001,1,1)\n",
    "#end_date = datetime(2018,6,30)\n",
    "\n",
    "# For New York\n",
    "city = 'ny/new-york/KNYC'\n",
    "start_date = datetime(2010,5,5)\n",
    "end_date = datetime.today()\n",
    "\n",
    "date_list = pd.Series(pd.date_range(start_date,end_date))\n",
    "date_list = [datetime.today()] ################# delete this ##################\n",
    "#city = 'ca/san-francisco/KSFO' ################ delete this ##################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for date in date_list:\n",
    "    \n",
    "    # Record start time (for scraper performance purposes)\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    url = 'https://www.wunderground.com/history/monthly/us/{loc}/date/{y}-{m}?cm_ven=localwx_history'\\\n",
    "          .format(loc=city, y=date.year, m=date.month)\n",
    "    driver.get(url)\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    webpage_data = []\n",
    "\n",
    "    # header stuff\n",
    "    pass\n",
    "    pass\n",
    "\n",
    "    # rows\n",
    "    row_idx = 3\n",
    "    column_idx = 0\n",
    "    subcolumn_idx = 0\n",
    "\n",
    "    # Iterate through rows\n",
    "    while True:\n",
    "        # For each row,\n",
    "        try:\n",
    "            # ...try to read the subcolumn at the following xpath to see if the row exists.\n",
    "            raw_datum = driver.find_element_by_xpath(xpath(row=row_idx,col=column_idx,sub=subcolumn_idx))\n",
    "\n",
    "            # If that worked, then initialize column_idx to 0 and row_data to [].\n",
    "            column_idx = 0\n",
    "            row_data = []\n",
    "\n",
    "            # Iterate through columns\n",
    "            while True:\n",
    "                # For each column,\n",
    "                try:\n",
    "                    # ...try to read the subcolumn at the following xpath to see if the column exists.\n",
    "                    raw_datum = driver.find_element_by_xpath(xpath(row=row_idx,col=column_idx,sub=subcolumn_idx))\n",
    "\n",
    "                    # If that worked, then initialize subcolumn_idx to 0 and column_data to [].\n",
    "                    subcolumn_idx = 0\n",
    "                    column_data = []\n",
    "\n",
    "                    # Iterate through subcolumns\n",
    "                    while True:\n",
    "                        # For each subcolumn,\n",
    "                        try:\n",
    "                            # ...try to read the subcolumn at the following xpath to see if it exists.\n",
    "                            raw_datum = driver.find_element_by_xpath(xpath(row=row_idx,col=column_idx,sub=subcolumn_idx))\n",
    "\n",
    "                            # If that worked, then try to convert raw_datum.text to a float.\n",
    "                            try:\n",
    "                                if column_idx == 0:\n",
    "                                    datum = int(raw_datum.text) # Store dates as integers.\n",
    "                                else:\n",
    "                                    datum = float(raw_datum.text) # Store measured values as floats.\n",
    "                            except:\n",
    "                                datum = float('nan') # Store dashes and anything that doesn't cooperate as NaNs.\n",
    "                            column_data.append(datum)\n",
    "\n",
    "                        except:\n",
    "                            # If it didn't work, there is no subcolumn at that index. Break subcolumn loop.\n",
    "                            break\n",
    "\n",
    "                        # next subcolumn\n",
    "                        subcolumn_idx += 1\n",
    "\n",
    "                    # That's it for the subcolumns in this column. Store column_data in row_data.\n",
    "                    row_data.extend(column_data)\n",
    "\n",
    "                except:\n",
    "                    #if it didn't work, there is no column at that index. \n",
    "                    break\n",
    "\n",
    "                # next column\n",
    "                column_idx += 1\n",
    "\n",
    "            # That's it for the columns in this row.\n",
    "\n",
    "        except:\n",
    "            # If it didn't work, there is no row at that index.\n",
    "            break\n",
    "\n",
    "        # next row\n",
    "        row_idx += 1\n",
    "\n",
    "    # That's it for the rows in the table. Store row_data in webpage_data. Done with this webpage!\n",
    "    webpage_data.append(row_data)\n",
    "\n",
    "\n",
    "\n",
    "    stop_time = datetime.now()\n",
    "    time_diff = stop_time-start_time\n",
    "    print('elapsed time:', time_diff.seconds + time_diff.microseconds/1000000, 's')\n",
    "    print(webpage_data)\n",
    "\n",
    "\n",
    "    myFile = open('example-NYC-{y}-{m}.csv'.format(y=date.year, m=date.month), 'w')\n",
    "    with myFile:\n",
    "        writer = csv.writer(myFile)\n",
    "        writer.writerows(webpage_data)\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 74.0, 69.0, 63.0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpage_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49920"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12*18 + 12*8\n",
    "312*160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.88888888888889"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
